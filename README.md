# ğŸ§¬ ScienceRAG

**AI-powered scientific literature intelligence platform**

Transform how you discover, synthesize, and understand academic research. Ask questions in natural language and get citation-backed answers synthesized from real scientific papers.

![ScienceRAG Demo](https://img.shields.io/badge/Status-Production%20Ready-green)
![Python](https://img.shields.io/badge/Python-3.12-blue)
![Next.js](https://img.shields.io/badge/Next.js-16-black)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

---

## âœ¨ Features

### ğŸ” **Intelligent Paper Discovery**
- Natural language queries â†’ relevant papers
- Searches **OpenAlex** (250M+ works) and **Semantic Scholar** (200M+ papers)
- Automatic deduplication across sources

### ğŸ§  **RAG-Powered Synthesis**
- Vector embeddings with OpenAI `text-embedding-3-small`
- Semantic search over chunked paper abstracts
- AI synthesis with inline citations

### ğŸ“Š **Real-Time Progress**
- Live sidebar showing ingestion progress
- Papers found, chunks created, embeddings generated
- Stage-by-stage pipeline visibility

### ğŸ¨ **Modern Chat Interface**
- Floating pill input (ChatGPT-style)
- Citation tooltips on hover
- Expandable source cards
- Settings panel with data source toggles

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone the repository
```bash
git clone https://github.com/HiNala/bio_hack.git
cd bio_hack
```

### 2. Create your `.env` file
```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:
```env
OPENAI_API_KEY=sk-your-key-here
```

### 3. Start all services
```bash
docker compose up --build -d
```

### 4. Open the app
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (Next.js)                       â”‚
â”‚  â€¢ Floating chat input                                       â”‚
â”‚  â€¢ Live progress sidebar                                     â”‚
â”‚  â€¢ Citation tooltips & source cards                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (FastAPI)                        â”‚
â”‚  â€¢ Query parsing & search term extraction                    â”‚
â”‚  â€¢ Literature API clients (OpenAlex, Semantic Scholar)       â”‚
â”‚  â€¢ Text chunking pipeline                                    â”‚
â”‚  â€¢ OpenAI embedding service                                  â”‚
â”‚  â€¢ Ingest job orchestration                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ Async PostgreSQL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATABASE (PostgreSQL + pgvector)            â”‚
â”‚  â€¢ Papers table with metadata                                â”‚
â”‚  â€¢ Chunks table with 1536-dim embeddings                     â”‚
â”‚  â€¢ Ingest jobs for progress tracking                         â”‚
â”‚  â€¢ HNSW index for fast similarity search                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
bio_hack/
â”œâ”€â”€ frontend/                 # Next.js 16 + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/             # App router pages
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â””â”€â”€ chat/        # Chat UI components
â”‚   â”‚   â””â”€â”€ lib/             # API client & utilities
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                  # FastAPI + Python 3.12
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ routes/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ schemas/         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ services/        # Business logic
â”‚   â”‚       â”œâ”€â”€ literature/  # OpenAlex & S2 clients
â”‚   â”‚       â”œâ”€â”€ chunking/    # Text chunking
â”‚   â”‚       â””â”€â”€ embedding/   # OpenAI embeddings
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docker/                   # Dockerfiles
â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â””â”€â”€ postgres.Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml        # Service orchestration
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ README.md
```

---

## ğŸ”Œ API Reference

### Start Ingestion Job
```http
POST /api/ingest
Content-Type: application/json

{
  "query": "double slit experiment with molecules",
  "max_results_per_source": 30
}
```

### Get Job Status (for polling)
```http
GET /api/ingest/{job_id}
```

Returns real-time progress:
```json
{
  "job_id": "uuid",
  "status": "embedding",
  "progress": {
    "papers": {
      "openalex_found": 47,
      "semantic_scholar_found": 32,
      "unique_papers": 61
    },
    "chunks": { "total_created": 183 },
    "embeddings": { "completed": 120, "total": 183, "percent": 65.6 }
  }
}
```

### Other Endpoints
| Endpoint | Description |
|----------|-------------|
| `GET /health` | Health check |
| `GET /documents` | List stored papers |
| `GET /chunk/stats` | Chunking statistics |
| `POST /embed/all` | Embed all chunks |
| `POST /search` | Semantic search |

Full API docs at: http://localhost:8000/docs

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for embeddings | âœ… Yes |
| `ANTHROPIC_API_KEY` | Anthropic key for synthesis | Optional |
| `OPENALEX_EMAIL` | Your email for faster API access | Optional |
| `DATABASE_URL` | PostgreSQL connection string | Auto-set |

### AI Models Used

| Task | Model | Why |
|------|-------|-----|
| Embeddings | `text-embedding-3-small` | Best value, 1536 dims |
| Query parsing | `gpt-4o-mini` | Fast, cost-effective |
| Synthesis | `gpt-4o-mini` / Claude | Configurable |

---

## ğŸ§ª Development

### Run locally without Docker

**Backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

### Run migrations
```bash
docker exec sciencerag-backend alembic upgrade head
```

### View logs
```bash
docker compose logs -f backend
docker compose logs -f frontend
```

---

## ğŸ¯ How It Works

### 1. User Query
```
"What are the leading interpretations of quantum mechanics since 2010?"
```

### 2. Query Parsing
Extracts search terms: `quantum mechanics interpretations`, `Copenhagen`, `many worlds`

### 3. Literature Fetch
- Queries OpenAlex and Semantic Scholar in parallel
- Deduplicates by DOI
- Stores papers with metadata

### 4. Chunking
- Splits abstracts into ~500 token chunks
- Maintains overlap for context

### 5. Embedding
- Generates 1536-dim vectors with OpenAI
- Stores in pgvector for fast similarity search

### 6. Response
- Shows papers found with citations
- Live progress in sidebar
- Expandable source cards

---

## ğŸ† Built For

**Agentic Orchestration Hackathon 2026**

This project demonstrates:
- Multi-source data aggregation
- RAG pipeline architecture
- Real-time progress tracking
- Production-ready infrastructure

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [OpenAlex](https://openalex.org/) - Open scholarly metadata
- [Semantic Scholar](https://www.semanticscholar.org/) - AI-powered research tool
- [pgvector](https://github.com/pgvector/pgvector) - Vector similarity for Postgres

---

## ğŸš€ Latest Features

### âœ¨ Enhanced User Experience
- **Progressive Web App (PWA)**: Installable on desktop and mobile with offline support
- **Advanced Loading States**: Beautiful skeleton screens and progress animations
- **Real-time Agent Activity**: Live tracking of AI processing with emoji indicators
- **Enhanced Keyboard Navigation**: Full keyboard support with shortcuts
- **Feedback Widget**: Built-in feedback collection for continuous improvement

### ğŸ›¡ï¸ Production-Ready Security
- **Rate Limiting**: Configurable API rate limits (RAG: 10/min, Ingest: 5/min)
- **Input Validation**: Comprehensive SQL injection and XSS protection
- **Request Logging**: Complete audit trail of all API interactions
- **Security Headers**: CORS, CSP, and other security best practices

### âš¡ Performance Optimizations
- **Service Worker**: Intelligent caching and offline functionality
- **Bundle Splitting**: Optimized webpack configuration for faster loads
- **Lazy Loading**: Components loaded on-demand for better initial performance
- **Database Caching**: Redis-backed caching with TTL for frequently accessed data
- **Performance Monitoring**: Built-in component render time tracking

### ğŸ”§ Developer Experience
- **Comprehensive Testing**: Backend and frontend test suites with 70%+ coverage
- **Error Boundaries**: Graceful error handling with user-friendly messages
- **TypeScript**: Full type safety with improved API contracts
- **Docker Optimization**: Multi-stage builds with security hardening
- **Hot Reload**: Enhanced development workflow

### ğŸ“Š Monitoring & Analytics
- **Health Endpoints**: Detailed system health and metrics
- **Application Metrics**: Papers, chunks, and job statistics
- **Performance Tracking**: Component render times and user interactions
- **Error Tracking**: Comprehensive error logging and reporting

### â™¿ Accessibility Improvements
- **ARIA Labels**: Complete screen reader support
- **Keyboard Navigation**: Full keyboard accessibility
- **Focus Management**: Visible focus indicators and logical tab order
- **Semantic HTML**: Proper heading structure and landmark roles

---

## ğŸ¯ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone and Setup
```bash
git clone https://github.com/HiNala/bio_hack.git
cd bio_hack
cp .env.example .env
# Edit .env with your OpenAI API key
```

### 2. Development Mode
```bash
docker compose up --build
```

### 3. Production Deployment
```bash
docker compose -f docker-compose.prod.yml up --build -d
```

### 4. Access Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                        â”‚
â”‚  â€¢ PWA with Service Worker                                  â”‚
â”‚  â€¢ Real-time agent activity tracking                        â”‚
â”‚  â€¢ Progressive loading with skeletons                       â”‚
â”‚  â€¢ Full accessibility support                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP/2 + WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                    BACKEND (FastAPI)                         â”‚
â”‚  â€¢ Rate limiting & input validation                          â”‚
â”‚  â€¢ Comprehensive logging & monitoring                        â”‚
â”‚  â€¢ Redis caching layer                                       â”‚
â”‚  â€¢ Async job processing                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ PostgreSQL + Redis
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚               DATABASE LAYER (Docker)                        â”‚
â”‚  â€¢ PostgreSQL with pgvector                                   â”‚
â”‚  â€¢ Redis for caching & sessions                              â”‚
â”‚  â€¢ Automated backups & health checks                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Security Features

- **API Rate Limiting**: Prevents abuse with configurable limits
- **Input Sanitization**: XSS and SQL injection protection
- **Request Validation**: Comprehensive input validation
- **CORS Configuration**: Secure cross-origin resource sharing
- **Audit Logging**: Complete request/response logging

---

## ğŸ“ˆ Performance Metrics

- **Bundle Size**: Optimized with code splitting (~150KB initial load)
- **Time to Interactive**: <2 seconds on modern connections
- **Offline Support**: Full PWA functionality
- **Caching Efficiency**: 90%+ cache hit rate for static assets
- **Database Queries**: Optimized with proper indexing

---

## ğŸ§ª Testing

```bash
# Backend tests
cd backend && pytest

# Frontend tests
cd frontend && npm test

# Coverage reports
cd backend && pytest --cov-report=html
cd frontend && npm run test:coverage
```

---

## ğŸ“š API Documentation

Complete API documentation available at `/docs` when running the application.

### Key Endpoints:
- `POST /api/ingest` - Start literature ingestion job
- `GET /api/ingest/{job_id}` - Monitor ingestion progress
- `POST /rag/ask` - Ask research questions
- `GET /health` - System health check
- `GET /metrics/health` - Detailed health metrics

---

## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

---

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

**Made with â¤ï¸ for researchers, by researchers**
