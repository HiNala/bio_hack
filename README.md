# ğŸ§¬ ScienceRAG

**AI-powered scientific literature intelligence platform**

Transform how you discover, synthesize, and understand academic research. Ask questions in natural language and get citation-backed answers synthesized from real scientific papers.

![ScienceRAG Demo](https://img.shields.io/badge/Status-Production%20Ready-green)
![Python](https://img.shields.io/badge/Python-3.12-blue)
![Next.js](https://img.shields.io/badge/Next.js-16-black)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

---

## âœ¨ Features

### ğŸ” **Intelligent Paper Discovery**
- Natural language queries â†’ relevant papers
- Searches **OpenAlex** (250M+ works) and **Semantic Scholar** (200M+ papers)
- Automatic deduplication across sources

### ğŸ§  **RAG-Powered Synthesis**
- Vector embeddings with OpenAI `text-embedding-3-small`
- Semantic search over chunked paper abstracts
- AI synthesis with inline citations

### ğŸ“Š **Real-Time Progress**
- Live sidebar showing ingestion progress
- Papers found, chunks created, embeddings generated
- Stage-by-stage pipeline visibility

### ğŸ¨ **Modern Chat Interface**
- Floating pill input (ChatGPT-style)
- Citation tooltips on hover
- Expandable source cards
- Settings panel with data source toggles

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone the repository
```bash
git clone https://github.com/HiNala/bio_hack.git
cd bio_hack
```

### 2. Create your `.env` file
```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:
```env
OPENAI_API_KEY=sk-your-key-here
```

### 3. Start all services
```bash
docker compose up --build -d
```

### 4. Open the app
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (Next.js)                       â”‚
â”‚  â€¢ Floating chat input                                       â”‚
â”‚  â€¢ Live progress sidebar                                     â”‚
â”‚  â€¢ Citation tooltips & source cards                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (FastAPI)                        â”‚
â”‚  â€¢ Query parsing & search term extraction                    â”‚
â”‚  â€¢ Literature API clients (OpenAlex, Semantic Scholar)       â”‚
â”‚  â€¢ Text chunking pipeline                                    â”‚
â”‚  â€¢ OpenAI embedding service                                  â”‚
â”‚  â€¢ Ingest job orchestration                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ Async PostgreSQL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATABASE (PostgreSQL + pgvector)            â”‚
â”‚  â€¢ Papers table with metadata                                â”‚
â”‚  â€¢ Chunks table with 1536-dim embeddings                     â”‚
â”‚  â€¢ Ingest jobs for progress tracking                         â”‚
â”‚  â€¢ HNSW index for fast similarity search                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
bio_hack/
â”œâ”€â”€ frontend/                 # Next.js 16 + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/             # App router pages
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â””â”€â”€ chat/        # Chat UI components
â”‚   â”‚   â””â”€â”€ lib/             # API client & utilities
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                  # FastAPI + Python 3.12
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ routes/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ schemas/         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ services/        # Business logic
â”‚   â”‚       â”œâ”€â”€ literature/  # OpenAlex & S2 clients
â”‚   â”‚       â”œâ”€â”€ chunking/    # Text chunking
â”‚   â”‚       â””â”€â”€ embedding/   # OpenAI embeddings
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docker/                   # Dockerfiles
â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â””â”€â”€ postgres.Dockerfile
â”‚
â”œâ”€â”€ docker-compose.yml        # Service orchestration
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ README.md
```

---

## ğŸ”Œ API Reference

### Start Ingestion Job
```http
POST /api/ingest
Content-Type: application/json

{
  "query": "double slit experiment with molecules",
  "max_results_per_source": 30
}
```

### Get Job Status (for polling)
```http
GET /api/ingest/{job_id}
```

Returns real-time progress:
```json
{
  "job_id": "uuid",
  "status": "embedding",
  "progress": {
    "papers": {
      "openalex_found": 47,
      "semantic_scholar_found": 32,
      "unique_papers": 61
    },
    "chunks": { "total_created": 183 },
    "embeddings": { "completed": 120, "total": 183, "percent": 65.6 }
  }
}
```

### Other Endpoints
| Endpoint | Description |
|----------|-------------|
| `GET /health` | Health check |
| `GET /documents` | List stored papers |
| `GET /chunk/stats` | Chunking statistics |
| `POST /embed/all` | Embed all chunks |
| `POST /search` | Semantic search |

Full API docs at: http://localhost:8000/docs

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for embeddings | âœ… Yes |
| `ANTHROPIC_API_KEY` | Anthropic key for synthesis | Optional |
| `OPENALEX_EMAIL` | Your email for faster API access | Optional |
| `DATABASE_URL` | PostgreSQL connection string | Auto-set |

### AI Models Used

| Task | Model | Why |
|------|-------|-----|
| Embeddings | `text-embedding-3-small` | Best value, 1536 dims |
| Query parsing | `gpt-4o-mini` | Fast, cost-effective |
| Synthesis | `gpt-4o-mini` / Claude | Configurable |

---

## ğŸ§ª Development

### Run locally without Docker

**Backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

### Run migrations
```bash
docker exec sciencerag-backend alembic upgrade head
```

### View logs
```bash
docker compose logs -f backend
docker compose logs -f frontend
```

---

## ğŸ¯ How It Works

### 1. User Query
```
"What are the leading interpretations of quantum mechanics since 2010?"
```

### 2. Query Parsing
Extracts search terms: `quantum mechanics interpretations`, `Copenhagen`, `many worlds`

### 3. Literature Fetch
- Queries OpenAlex and Semantic Scholar in parallel
- Deduplicates by DOI
- Stores papers with metadata

### 4. Chunking
- Splits abstracts into ~500 token chunks
- Maintains overlap for context

### 5. Embedding
- Generates 1536-dim vectors with OpenAI
- Stores in pgvector for fast similarity search

### 6. Response
- Shows papers found with citations
- Live progress in sidebar
- Expandable source cards

---

## ğŸ† Built For

**Agentic Orchestration Hackathon 2026**

This project demonstrates:
- Multi-source data aggregation
- RAG pipeline architecture
- Real-time progress tracking
- Production-ready infrastructure

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [OpenAlex](https://openalex.org/) - Open scholarly metadata
- [Semantic Scholar](https://www.semanticscholar.org/) - AI-powered research tool
- [pgvector](https://github.com/pgvector/pgvector) - Vector similarity for Postgres

---

**Made with â¤ï¸ for researchers, by researchers**
